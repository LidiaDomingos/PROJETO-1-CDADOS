{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Layne Silva\n",
    "\n",
    "Nome: Lidia Domingos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lidia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from string import punctuation\n",
    "import nltk \n",
    "from nltk.stem import RSLPStemmer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\lidia\\Desktop\\Ci√™ncia dos Dados\\Projeto1\\PROJETO-1-CDADOS\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'XIAOMI.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TREINAMENTO</th>\n",
       "      <th>CLASSIFICA√á√ÉO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quem aqui tb pronuncia xiaomi xaiomi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xiaomi mi true airdots 2s earphone(aliexpress)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@felpsflip carreguei meu xiaomi uma vez na vid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#promo #\\n$133.99 ~ 111,85 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#promo #\\n$299.99 ~ 250,41 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         TREINAMENTO  CLASSIFICA√á√ÉO\n",
       "0               quem aqui tb pronuncia xiaomi xaiomi              0\n",
       "1  xiaomi mi true airdots 2s earphone(aliexpress)...              0\n",
       "2  @felpsflip carreguei meu xiaomi uma vez na vid...              1\n",
       "3  #promo #\\n$133.99 ~ 111,85 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cup...              0\n",
       "4  #promo #\\n$299.99 ~ 250,41 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cup...              0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>CLASSIFICA√á√ÉO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#promo #\\n$11.99 ~ 10,01 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cupon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üí†xiaomi poco m3 \\n\\nüíµ por:  r$ 728,27 64gb\\nüíµ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_faccin_ \"quem ai tem um xiaomi pra ligar o p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comprei mais capinha pro xiaomi https://t.co/7...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#promo√ß√£o #oferta \\n\\nüíµ por: r$ 1420 \\nüõí link:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  CLASSIFICA√á√ÉO\n",
       "0  #promo #\\n$11.99 ~ 10,01 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cupon...              0\n",
       "1  üí†xiaomi poco m3 \\n\\nüíµ por:  r$ 728,27 64gb\\nüíµ ...              0\n",
       "2  @_faccin_ \"quem ai tem um xiaomi pra ligar o p...              0\n",
       "3  comprei mais capinha pro xiaomi https://t.co/7...              0\n",
       "4  #promo√ß√£o #oferta \\n\\nüíµ por: r$ 1420 \\nüõí link:...              0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "ESCREVA AQUI...\n",
    "\n",
    "*Escolhida a empresa XIAOMI, classificamos como tweets relevantes toda e qualquer cita√ß√£o (seja ela positiva ou negativa) dos internautas falando sobre o produto. Tweets considerados como irrelevantes seriam tweets n√£o relacionados diretamente ao produto.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpeza de mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.\n",
    "#Corre√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "#Proposta de outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n",
    "import re \n",
    "from nltk.tokenize.casual import TweetTokenizer #separa os emojis como palavras.\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-@.[\\]:\"?;\\),(\"/]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = re.sub(r'http\\S+', '',text_subbed)\n",
    "    t = TweetTokenizer()\n",
    "    text_subbed = t.tokenize(text_subbed) \n",
    "    return text_subbed\n",
    "\n",
    "def RemoveStopWords(list_of_words):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    filtered = []\n",
    "    for word in list_of_words:\n",
    "        if word not in stopwords:\n",
    "            filtered.append(word)\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUNTANDO TODAS AS PALAVRAS DOS TWEETS RELEVANTES DO TREINAMENTO\n",
    "train_relevante = train.loc[train[\"CLASSIFICA√á√ÉO\"] == 1, :]\n",
    "train_relevante_filtrada = ' '.join(train_relevante.TREINAMENTO) \n",
    "\n",
    "#JUNTANDO TODAS AS PALAVRAS DOS TWEETS IRRELEVANTES DO TREINAMENTO\n",
    "train_irrelevante = train.loc[train[\"CLASSIFICA√á√ÉO\"] == 0, :]\n",
    "train_irrelevante_filtrada = ' '.join(train_irrelevante.TREINAMENTO) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPANDO VARI√ÅVEIS CRIADAS, COLOCANDO EM MIN√öSCULO E AS GUARDANDO\n",
    "relevante = cleanup(train_relevante_filtrada.lower())\n",
    "relevantes = RemoveStopWords(relevante)\n",
    "\n",
    "irrelevante = cleanup(train_irrelevante_filtrada.lower())\n",
    "irrelevantes = RemoveStopWords(relevantes)\n",
    "\n",
    "#JUNTANDO OS CONJUNTOS\n",
    "total = relevantes + irrelevantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORMANDO EM PD.SERIES\n",
    "series_train_global = pd.Series(total)\n",
    "series_train_relevante = pd.Series(relevantes)\n",
    "series_train_irrelevante = pd.Series(irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FREQU√äNCIAS RELATIVAS\n",
    "train_global_relativas = series_train_global.value_counts(True)\n",
    "train_relevante_relativas = series_train_relevante.value_counts(True)\n",
    "train_irrelevante_relativas = series_train_irrelevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FREQU√äNCIAS ABSOLUTAS\n",
    "train_relevante_absolutas = series_train_relevante.value_counts()\n",
    "train_irrelevante_absolutas = series_train_irrelevante.value_counts()\n",
    "train_global_absolutas = series_train_global.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EVENTOS**\n",
    "\n",
    " * $R$: coment√°rios relevantes\n",
    " * $R^c$: coment√°rios irrelevantes\n",
    " * $C$: coment√°rio recebido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBABILIDADES**\n",
    "\n",
    " * $P(R)$ : probabilidade do coment√°rio ser relevante ;\n",
    " * $P(R^c)$: probabilidade do coment√°rio n√£o ser relevante, ou seja, irrelevante ;\n",
    " * $P(C)$ : probabilidade de cada palavra ocorrer na l√≠ngua portuguesa ;\n",
    " * $P(C|R)$ : probabilidade do coment√°rio existir dado o conjunto de relevantes ;\n",
    " * $P(C|R^c)$: probabilidade do coment√°rio existir dado o conjunto de irrelevantes ; \n",
    " * $P(R|C)$: probabilidade do coment√°rio ser relevante dado a frase ;\n",
    " * $P(R^c|C)$: probabilidade do coment√°rio ser irrelevante dado a frase;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_R = (train_relevante_absolutas.sum())/(train_global_absolutas.sum())\n",
    "P_Rc =  (train_irrelevante_absolutas.sum())/(train_global_absolutas.sum())\n",
    "P_R + P_Rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_C_dado_R = train_relevante_relativas[total].prod()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
