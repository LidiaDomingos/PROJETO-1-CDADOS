{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo do projeto\n",
    "\n",
    "\n",
    "\"Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um\n",
    "determinado produto no Twitter. A empresa deseja que voc√™: crie um programa que selecione\n",
    "algumas mensagens dispon√≠veis no Twitter, as quais mencionam esse particular produto; e\n",
    "classifique esses tweets como \"relevante\" ou \"irrelevante\", pelo menos.\n",
    "Com isso, essa empresa deseja que mensagens relevantes, que denigrem o nome do produto, ou\n",
    "que mere√ßam destaque, por exemplo, disparem um foco de aten√ß√£o da √°rea de marketing.\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do\n",
    "Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails, por exemplo.\n",
    "Esse classificador permite calcular qual a probabilidade de uma mensagem ser relevante dada as\n",
    "palavras em seu conte√∫do.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, voc√™ precisa implementar uma vers√£o\n",
    "do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a\n",
    "performance dos resultados com uma base de testes.\n",
    "\n",
    "Ap√≥s validado, o seu prot√≥tipo poderia, porque n√£o, tamb√©m capturar e classificar\n",
    "automaticamente as mensagens da plataforma\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribuidores: \n",
    "\n",
    "Layne Silva\n",
    "\n",
    "Lidia Domingos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando bibliotecas utilizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\layneps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk \n",
    "from nltk.stem import RSLPStemmer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diret√≥rio utilizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\layneps\\Desktop\\Insper\\CDados\\PROJETO 1\\PROJETO-1-CDADOS\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando a base de dados e visualizando 5 primeiros termos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrindo excel:\n",
    "filename = 'XIAOMI.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TREINAMENTO</th>\n",
       "      <th>CLASSIFICA√á√ÉO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quem aqui tb pronuncia xiaomi xaiomi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xiaomi mi true airdots 2s earphone(aliexpress)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@felpsflip carreguei meu xiaomi uma vez na vid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#promo #\\n$133.99 ~ 111,85 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#promo #\\n$299.99 ~ 250,41 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         TREINAMENTO  CLASSIFICA√á√ÉO\n",
       "0               quem aqui tb pronuncia xiaomi xaiomi              0\n",
       "1  xiaomi mi true airdots 2s earphone(aliexpress)...              0\n",
       "2  @felpsflip carreguei meu xiaomi uma vez na vid...              1\n",
       "3  #promo #\\n$133.99 ~ 111,85 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cup...              0\n",
       "4  #promo #\\n$299.99 ~ 250,41 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cup...              0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Armazenando excel dos dados de TREINAMENTO em uma vari√°vel e visualizando 5 primeiros termos:\n",
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>CLASSIFICA√á√ÉO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#promo #\\n$11.99 ~ 10,01 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cupon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üí†xiaomi poco m3 \\n\\nüíµ por:  r$ 728,27 64gb\\nüíµ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_faccin_ \"quem ai tem um xiaomi pra ligar o p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comprei mais capinha pro xiaomi https://t.co/7...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#promo√ß√£o #oferta \\n\\nüíµ por: r$ 1420 \\nüõí link:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  CLASSIFICA√á√ÉO\n",
       "0  #promo #\\n$11.99 ~ 10,01 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cupon...              0\n",
       "1  üí†xiaomi poco m3 \\n\\nüíµ por:  r$ 728,27 64gb\\nüíµ ...              0\n",
       "2  @_faccin_ \"quem ai tem um xiaomi pra ligar o p...              0\n",
       "3  comprei mais capinha pro xiaomi https://t.co/7...              0\n",
       "4  #promo√ß√£o #oferta \\n\\nüíµ por: r$ 1420 \\nüõí link:...              0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Armazenando excel dos dados de TESTE em uma vari√°vel e visualizando 5 primeiros termos:\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#promo #\\n$11.99 ~ 10,01 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cupon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üí†xiaomi poco m3 \\n\\nüíµ por:  r$ 728,27 64gb\\nüíµ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_faccin_ \"quem ai tem um xiaomi pra ligar o p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comprei mais capinha pro xiaomi https://t.co/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#promo√ß√£o #oferta \\n\\nüíµ por: r$ 1420 \\nüõí link:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>rt @victorxama: salve rapa, t√¥ vendendo meu xi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>@mslaryhill tenho um haylou gt1 pro q √© da mes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>@gabiiii__araujo üò±üò±üò±\\n\\n*baixou mais!!*\\n\\n*xi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>@inutializador @viniport0 @2kjuramento @pessoa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>rt @amt_online: saiba como usar o celular sem ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste\n",
       "0    #promo #\\n$11.99 ~ 10,01 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cupon...\n",
       "1    üí†xiaomi poco m3 \\n\\nüíµ por:  r$ 728,27 64gb\\nüíµ ...\n",
       "2    @_faccin_ \"quem ai tem um xiaomi pra ligar o p...\n",
       "3    comprei mais capinha pro xiaomi https://t.co/7...\n",
       "4    #promo√ß√£o #oferta \\n\\nüíµ por: r$ 1420 \\nüõí link:...\n",
       "..                                                 ...\n",
       "254  rt @victorxama: salve rapa, t√¥ vendendo meu xi...\n",
       "255  @mslaryhill tenho um haylou gt1 pro q √© da mes...\n",
       "256  @gabiiii__araujo üò±üò±üò±\\n\\n*baixou mais!!*\\n\\n*xi...\n",
       "257  @inutializador @viniport0 @2kjuramento @pessoa...\n",
       "258  rt @amt_online: saiba como usar o celular sem ...\n",
       "\n",
       "[259 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecionando linhas dos dados TESTE pelo m√©todo de sele√ß√£o ILOC:\n",
    "test.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descri√ß√£o do produto escolhido\n",
    "    \n",
    "    A empresa escolhida foi a Xiaomi, \"uma empresa multinacional chinesa do ramo da tecnologia e manufatura de produtos eletr√¥nicos com sede em Pequim. A Xiaomi desenvolve, investe, produz e distribui smartphones, notebooks, smartbands, fones de ouvido, televis√µes, dispositivos para casas inteligentes, e muitos outros produtos.\"\n",
    "    \n",
    "    Fonte: https://pt.wikipedia.org/wiki/Xiaomi\n",
    "   \n",
    "\n",
    "## Crit√©rios de classifica√ß√£o dos tweets:\n",
    "    Escolhida a empresa e seus produtos, classificamos como tweets relevantes toda e qualquer cita√ß√£o, positiva ou negativa, referente √†s cita√ß√µes dos internautas acerca do produto. Tweets considerados como \"irrelevantes\" foram denominados como tweets n√£o relacionados diretamente ao produto. Al√©m disso, os tweets considerados relevantes expressavam algum sentimento em rela√ß√£o aos produtos da empresa, seja de felicidade, ansiedade acerca da compra, tristeza, decep√ß√£o, entre outros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Montando um Classificador Naive-Bayes\n",
    "\n",
    "O algoritmo ‚ÄúNaive Bayes‚Äù √© um classificador probabil√≠stico muito utilizado em machine learning. Baseado no ‚ÄúTeorema de Bayes‚Äù, o modelo foi criado por um matem√°tico ingl√™s, e tamb√©m ministro presibiteriano, chamado Thomas Bayes (1701 ‚Äì 1761) para tentar provar a exist√™ncia de Deus.\n",
    "\n",
    "Hoje √© tamb√©m utilizado na √°rea de Aprendizado de M√°quina (Machine Learning) para categorizar textos com base na frequ√™ncia das palavras usadas.\n",
    "\n",
    "Entre as possibilidades de aplica√ß√µes est√° a classifica√ß√£o de um e-mail como SPAM ou N√£o-SPAM e a identifica√ß√£o de um assunto com base em seu conte√∫do.\n",
    "\n",
    "Ele recebe o nome de ‚Äúnaive‚Äù (ing√™nuo) porque desconsidera a correla√ß√£o entre as vari√°veis (features). Ou seja, se determinada fruta √© rotulada como ‚ÄúLim√£o‚Äù, caso ela tamb√©m seja descrita como ‚ÄúVerde‚Äù e ‚ÄúRedonda‚Äù, o algoritmo n√£o vai levar em considera√ß√£o a correla√ß√£o entre esses fatores. Isso porque trata cada um de forma independente.\n",
    "\n",
    "Fonte: https://www.datageeks.com.br/naive-bayes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EVENTOS**\n",
    "\n",
    " * $R$: tweets relevantes\n",
    " * $R^c$: tweets irrelevantes\n",
    " * $C$: tweet recebido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBABILIDADES**\n",
    "\n",
    " * $P(R)$ : probabilidade de um tweet ser relevante ;\n",
    " * $P(R^c)$: probabilidade de um tweet n√£o ser relevante, ou seja, irrelevante ;\n",
    " * $P(C)$ : probabilidade de cada tweet ocorrer na l√≠ngua portuguesa ;\n",
    " * $P(C|R)$ : probabilidade do tweet existir dado o conjunto de tweets relevantes ;\n",
    " * $P(C|R^c)$: probabilidade do tweet existir dado o conjunto de tweets irrelevantes ; \n",
    " * $P(R|C)$: probabilidade do tweet ser relevante dado a frase ;\n",
    " * $P(R^c|C)$: probabilidade do tweet ser irrelevante dado a frase;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$P(R|C) = \\frac{P(C|R) \\cdot P(R)}{P(C)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√µes criadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando novas bibliotecas importantes para constru√ß√£o das fun√ß√µes:\n",
    "import re \n",
    "from nltk.tokenize.casual import TweetTokenizer #separa os emojis como palavras.\n",
    "\n",
    "#Limpeza de mensagens removendo os caracteres: enter, :, \", ', (, ), etc sem remo√ß√£o de emojis + outras propostas de limpezas:\n",
    "def cleanup(text):\n",
    "    #import string\n",
    "    punctuation = '[!-@.~[\\]:\"''?;\\),(\"/]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = re.sub(r'http\\S+', '',text_subbed)\n",
    "    t = TweetTokenizer()\n",
    "    text_subbed = t.tokenize(text_subbed) \n",
    "    return text_subbed\n",
    "\n",
    "#Corre√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "def RemoveStopWords(list_of_words):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    lista_filtrada = []\n",
    "    for word in list_of_words:\n",
    "        if word not in stopwords:\n",
    "            lista_filtrada.append(word)\n",
    "    return lista_filtrada\n",
    "\n",
    "#Prever classe do conjunto, resolver problema de frequ√™ncia zero\n",
    "def Suavizacao_Laplace(variavel1, variavel2, variavel3):\n",
    "    y = (1 + variavel1)/(variavel2 + len(variavel3))  \n",
    "    return y\n",
    "\n",
    "#Multiplicando valores de listas\n",
    "def MultiplyList(List) : \n",
    "    result = 1\n",
    "    for x in List: \n",
    "         result = result * x  \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando vari√°veis com palavras juntadas e as limpando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUNTANDO TODAS AS PALAVRAS DOS TWEETS RELEVANTES DO TREINAMENTO\n",
    "train_relevante = train.loc[train[\"CLASSIFICA√á√ÉO\"] == 1, :]\n",
    "train_relevante_filtrada = ' '.join(train_relevante.TREINAMENTO) \n",
    "\n",
    "#JUNTANDO TODAS AS PALAVRAS DOS TWEETS IRRELEVANTES DO TREINAMENTO\n",
    "train_irrelevante = train.loc[train[\"CLASSIFICA√á√ÉO\"] == 0, :]\n",
    "train_irrelevante_filtrada = ' '.join(train_irrelevante.TREINAMENTO) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPANDO VARI√ÅVEIS CRIADAS, COLOCANDO EM MIN√öSCULO E AS GUARDANDO\n",
    "relevante = cleanup(train_relevante_filtrada.lower())\n",
    "palavras_relevantes = RemoveStopWords(relevante)\n",
    "\n",
    "irrelevante = cleanup(train_irrelevante_filtrada.lower())\n",
    "palavras_irrelevantes = RemoveStopWords(irrelevante)\n",
    "\n",
    "#JUNTANDO OS CONJUNTOS\n",
    "palavras_total = palavras_relevantes + palavras_irrelevantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORMANDO EM PD.SERIES\n",
    "series_total = pd.Series(palavras_total)\n",
    "series_train_relevante = pd.Series(palavras_relevantes)\n",
    "series_train_irrelevante = pd.Series(palavras_irrelevantes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo c√°lculo de frequ√™ncias:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FREQU√äNCIAS RELATIVAS\n",
    "\n",
    "palavras_total_relativas = series_total.value_counts(True)\n",
    "palavras_relevante_relativas = series_train_relevante.value_counts(True)\n",
    "palavras_irrelevante_relativas = series_train_irrelevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FREQU√äNCIAS ABSOLUTAS\n",
    "\n",
    "palavras_relevante_absolutas = series_train_relevante.value_counts()\n",
    "palavras_irrelevante_absolutas = series_train_irrelevante.value_counts()\n",
    "palavras_total_absolutas = series_total.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atribuindo fun√ß√£o ao classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_classificadora(test):\n",
    "    \n",
    "    lista_resultados = []\n",
    "    \n",
    "    test['Classifica√ß√£o_NB'] = 'NaN'\n",
    "    \n",
    "    for tweet in list(test.Teste):\n",
    "        \n",
    "        tweet_limpo = RemoveStopWords(cleanup(tweet.lower()))\n",
    "        lista_de_probabilidades1 = []\n",
    "        lista_de_probabilidades2 = []\n",
    "        \n",
    "        for palavra in tweet_limpo:\n",
    "            \n",
    "            if (palavra in palavras_relevante_absolutas) & (palavra not in palavras_irrelevante_absolutas):\n",
    "                Laplace = Suavizacao_Laplace(palavras_relevante_absolutas[palavra],palavras_relevante_absolutas.sum(),palavras_total_absolutas)\n",
    "                lista_de_probabilidades1.append(Laplace)\n",
    "                Laplace = Suavizacao_Laplace(0,palavras_irrelevante_absolutas.sum(),palavras_total_absolutas)\n",
    "                lista_de_probabilidades2.append(Laplace)\n",
    "                \n",
    "            elif (palavra not in palavras_relevante_absolutas) & (palavra in palavras_irrelevante_absolutas):\n",
    "                Laplace = Suavizacao_Laplace(palavras_irrelevante_absolutas[palavra],palavras_irrelevante_absolutas.sum(),palavras_total_absolutas)\n",
    "                lista_de_probabilidades2.append(Laplace)\n",
    "                Laplace = Suavizacao_Laplace(0,palavras_relevante_absolutas.sum(),palavras_total_absolutas)\n",
    "                lista_de_probabilidades1.append(Laplace)\n",
    "                \n",
    "            elif (palavra in palavras_relevante_absolutas) & (palavra in palavras_irrelevante_absolutas):\n",
    "                Laplace = Suavizacao_Laplace(palavras_relevante_absolutas[palavra],palavras_relevante_absolutas.sum(),palavras_total_absolutas)\n",
    "                lista_de_probabilidades1.append(Laplace)\n",
    "                Laplace = Suavizacao_Laplace(palavras_irrelevante_absolutas[palavra],palavras_irrelevante_absolutas.sum(),palavras_total_absolutas)\n",
    "                lista_de_probabilidades2.append(Laplace)\n",
    "            \n",
    "            elif palavra == 'xiaomi':\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                Laplace = Suavizacao_Laplace(0,palavras_relevante_absolutas.sum(),palavras_total_absolutas)\n",
    "                lista_de_probabilidades1.append(Laplace)\n",
    "                Laplace = Suavizacao_Laplace(0,palavras_irrelevante_absolutas.sum(),palavras_total_absolutas)\n",
    "                lista_de_probabilidades2.append(Laplace)\n",
    "                \n",
    "            P_C_dado_R = MultiplyList(lista_de_probabilidades1)\n",
    "            P_C_dado_Rc = MultiplyList(lista_de_probabilidades2)\n",
    "\n",
    "        P_R = (palavras_relevante_absolutas.sum())/(palavras_total_absolutas.sum())\n",
    "    \n",
    "        P_Rc = 1 - P_R\n",
    "        \n",
    "        P_R_dado_C = P_R * P_C_dado_R\n",
    "\n",
    "        P_Rc_dado_C = P_Rc * P_C_dado_Rc            \n",
    "        \n",
    "        if P_R_dado_C > P_Rc_dado_C:\n",
    "            resultado = 1\n",
    "        else:\n",
    "            resultado = 0\n",
    "        \n",
    "        lista_resultados.append(resultado)\n",
    "    test['Classifica√ß√£o_NB'] = lista_resultados\n",
    "    return test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Verificando a performance do classificador e resultados:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>CLASSIFICA√á√ÉO</th>\n",
       "      <th>Classifica√ß√£o_NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#promo #\\n$11.99 ~ 10,01 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cupon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üí†xiaomi poco m3 \\n\\nüíµ por:  r$ 728,27 64gb\\nüíµ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_faccin_ \"quem ai tem um xiaomi pra ligar o p...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comprei mais capinha pro xiaomi https://t.co/7...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#promo√ß√£o #oferta \\n\\nüíµ por: r$ 1420 \\nüõí link:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>rt @victorxama: salve rapa, t√¥ vendendo meu xi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>@mslaryhill tenho um haylou gt1 pro q √© da mes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>@gabiiii__araujo üò±üò±üò±\\n\\n*baixou mais!!*\\n\\n*xi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>@inutializador @viniport0 @2kjuramento @pessoa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>rt @amt_online: saiba como usar o celular sem ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  CLASSIFICA√á√ÉO  \\\n",
       "0    #promo #\\n$11.99 ~ 10,01 ‚Ç¨ ‚úÇÔ∏ècup√£o/cupom/cupon...              0   \n",
       "1    üí†xiaomi poco m3 \\n\\nüíµ por:  r$ 728,27 64gb\\nüíµ ...              0   \n",
       "2    @_faccin_ \"quem ai tem um xiaomi pra ligar o p...              0   \n",
       "3    comprei mais capinha pro xiaomi https://t.co/7...              0   \n",
       "4    #promo√ß√£o #oferta \\n\\nüíµ por: r$ 1420 \\nüõí link:...              0   \n",
       "..                                                 ...            ...   \n",
       "254  rt @victorxama: salve rapa, t√¥ vendendo meu xi...              0   \n",
       "255  @mslaryhill tenho um haylou gt1 pro q √© da mes...              1   \n",
       "256  @gabiiii__araujo üò±üò±üò±\\n\\n*baixou mais!!*\\n\\n*xi...              0   \n",
       "257  @inutializador @viniport0 @2kjuramento @pessoa...              1   \n",
       "258  rt @amt_online: saiba como usar o celular sem ...              0   \n",
       "\n",
       "     Classifica√ß√£o_NB  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   0  \n",
       "..                ...  \n",
       "254                 0  \n",
       "255                 1  \n",
       "256                 0  \n",
       "257                 1  \n",
       "258                 1  \n",
       "\n",
       "[259 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = funcao_classificadora(test)\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Irrelevante', 'Relevante'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo vari√°veis da planilha como vari√°veis categ√≥ricas e suas respectivas categorias \n",
    "teste['CLASSIFICA√á√ÉO'] = teste['CLASSIFICA√á√ÉO'].astype('category')\n",
    "teste['CLASSIFICA√á√ÉO'].cat.categories = ['Irrelevante', 'Relevante']\n",
    "teste['CLASSIFICA√á√ÉO'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Irrelevante', 'Relevante'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo vari√°veis do classificador como vari√°veis categ√≥ricas e suas respectivas categorias \n",
    "teste['Classifica√ß√£o_NB'] = teste['Classifica√ß√£o_NB'].astype('category')\n",
    "teste['Classifica√ß√£o_NB'].cat.categories = ['Irrelevante', 'Relevante']\n",
    "teste['Classifica√ß√£o_NB'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CLASSIFICA√á√ÉO</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o_NB</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.3089</td>\n",
       "      <td>0.0656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.4595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "CLASSIFICA√á√ÉO     Irrelevante  Relevante\n",
       "Classifica√ß√£o_NB                        \n",
       "Irrelevante            0.3089     0.0656\n",
       "Relevante              0.1660     0.4595"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparando resultados das classica√ß√£o entre o planilha e o classificador Naive Bayes por meio do comando CrossTab\n",
    "\n",
    "tabela = pd.crosstab(teste.Classifica√ß√£o_NB, teste.CLASSIFICA√á√ÉO, normalize = True).round(4)\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo contagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros positivos √©: 45.950%\n",
      "\n",
      "A porcentagem de falsos positivos √©: 16.600%\n",
      "\n",
      "A porcentagem de verdadeiros negativos √©: 30.890%\n",
      "\n",
      "A porcentagem de falsos negativos √©: 6.560%\n",
      "\n",
      "Portanto, a efic√°cia do classificador √© de: 76.84%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.159999999999997"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verdadeiros_positivos = tabela.iloc[1,1]*100\n",
    "falsos_positivos = tabela.iloc[1,0]*100\n",
    "verdadeiros_negativos = tabela.iloc[0,0]*100\n",
    "falsos_negativos = tabela.iloc[0,1]*100\n",
    "\n",
    "#calculando efic√°cia:\n",
    "eficacia = verdadeiros_positivos + verdadeiros_negativos\n",
    "eficacia\n",
    "\n",
    "print('A porcentagem de verdadeiros positivos √©: {:.3f}%\\n'.format(verdadeiros_positivos))\n",
    "print('A porcentagem de falsos positivos √©: {:.3f}%\\n'.format(falsos_positivos))\n",
    "print('A porcentagem de verdadeiros negativos √©: {:.3f}%\\n'.format(verdadeiros_negativos))\n",
    "print('A porcentagem de falsos negativos √©: {:.3f}%\\n'.format(falsos_negativos))\n",
    "print('Portanto, a efic√°cia do classificador √© de: {:.2f}%\\n'.format(eficacia))\n",
    "\n",
    "# ----\n",
    "teste = 100 - eficacia \n",
    "teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Conclus√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Comparativos qualitativos:\n",
    "\n",
    "    Dada a jun√ß√£o das porcentagens de verdadeiros positivos e verdadeiros negativos, foi poss√≠vel perceber que a efic√°cia do classificador foi de 76,84%. Isso evid√™ncia que de um total de 100%, apenas existiria aproximadamente 23,16% de \"falha\" do classificador, classificando o classificador como bom. Apesar de terem que ser realizadas muitas melhorias, a porcentagem de verdadeiros positivos em compara√ß√£o com verdadeiros negativos e a porcentagem de falsos positivos em compara√ß√£o a falsos negativos, em ambos os casos, se sobressaem, reafirmando a classifica√ß√£o designada ao Bayes.\n",
    "    Acerca das mensagens tratadas com dupla nega√ß√£o e sacarmo, estas n√£o foram interpretadas pelo classificador, uma vez que a parte ing√™nua do Naive Bayes consiste em assumir que as palavras s√£o independentes entre si e que sua ordem na frase n√£o importa, assim ignorando esse tratamento.\n",
    " \n",
    "    - ### Por qual motivo a base de treinamento n√£o pode ser alimentada automaticamente pelo pr√≥prio classificador?\n",
    "        Por conta da ingenuidade do classificador ao assumir que as palavras s√£o independentes, torna-se invi√°vel a classifica√ß√£o autom√°ticada de tweets, uma vez que a classifica√ß√£o se tornaria largamente imprecisa. Nesse contexto, ao chegarem novos tweets para serem classificados na base de dados, n√£o seria poss√≠vel ter um resultado preciso se fosse classificado automaticamente, pois com uma amplitude maior por parte das classifica√ß√µes incorretas e, consequentemente, as probabilidades retornadas pelo modelo tamb√©m estariam incorretas, tornando os resultados muito imprecisos.\n",
    "\n",
    "    - ### Projeto de expans√£o e melhorias do classificador\n",
    "        Dada a ingenuidade do classificador, seria interessante se fosse poss√≠vel a troca do classificador por outro mais preciso (como citados nesse link (https://bitlybr.com/87Uwox). Ou at√© melhorar o Bayes em termos de precis√£o para ter resultados cada vez mais convincentes, mas para isso, uma das possibilidades seria a combina√ß√£o com outros classificadores que objetificam a \"depend√™ncia entre elementos\", como explicado no artigo cient√≠fico de Alo√≠sio Carlos de Pina e Gerson Zaverucha realizado na Universidade Federal do Rio de Janeiro (UFRJ) (https://www.cos.ufrj.br/~ines/enia07_html/pdf/28095.pdf).\n",
    "        Outra melhora a ser citada e um poss√≠vel projeto expans√£o, seria primeiramente, dentro das cita√ß√µes acerca da empresa (grupo de relevantes) os classificar em novas categorias, como \"Favor√°veis\" e \"Desfavor√°veis\" por exemplo, voltado para algum produto espec√≠fico dentro da empresa. Isso objetificaria ainda mais o resultado e tornaria algo bem mais espec√≠fico. Al√©m do que, trazer mais dados ao banco de dados tamb√©m seria muito interessante do ponto de vista de resultado e precis√£o. Com isso, o motivo para ter uma continuidade de financiamento, seria as possibilidades que essas melhorias e expans√µes trariam. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- ### Proposta do classificador em outros contextos\n",
    "    O classificador Naive Bayes poderia ser utilizados em outros contextos \n",
    "        IDENTIFICA√á√ÉO DE FALHAS\n",
    "         Pense em outros cen√°rios sem intersec√ß√£o com este projeto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "https://pt.wikipedia.org/wiki/Xiaomi\n",
    "\n",
    "https://www.datageeks.com.br/naive-bayes/\n",
    "\n",
    "https://www.cos.ufrj.br/~ines/enia07_html/pdf/28095.pdf\n",
    "\n",
    "https://bitlybr.com/87Uwox\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
